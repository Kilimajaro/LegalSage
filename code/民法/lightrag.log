2025-03-07 19:53:45,705 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-07 19:53:45,705 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x0000025850C98D60>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x0000025850C98CC0>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x00000258502F40E0>

2025-03-07 19:53:45,705 - lightrag - INFO - Load KV full_docs with 0 data
2025-03-07 19:53:45,705 - lightrag - INFO - Load KV text_chunks with 0 data
2025-03-07 19:53:45,705 - lightrag - INFO - Load KV llm_response_cache with 0 data
2025-03-07 20:02:30,185 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-07 20:02:30,187 - lightrag - INFO - [New Docs] inserting 1 docs
2025-03-07 20:02:30,378 - lightrag - INFO - [New Chunks] inserting 1 chunks
2025-03-07 20:02:30,383 - lightrag - INFO - Inserting 1 vectors to chunks
2025-03-07 20:02:31,320 - lightrag - INFO - [Entity Extraction]...
2025-03-07 20:03:15,570 - lightrag - INFO - Inserting 15 vectors to entities
2025-03-07 20:03:16,254 - lightrag - INFO - Inserting 18 vectors to relationships
2025-03-07 20:03:16,984 - lightrag - INFO - Writing graph with 18 nodes, 18 edges
2025-03-07 20:23:54,442 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-07 20:23:54,442 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x000001F273DF8D60>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x000001F273DF8CC0>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x000001F2734580E0>

2025-03-07 20:23:54,446 - lightrag - INFO - Load KV full_docs with 1 data
2025-03-07 20:23:54,446 - lightrag - INFO - Load KV text_chunks with 1 data
2025-03-07 20:23:54,446 - lightrag - INFO - Load KV llm_response_cache with 2 data
2025-03-07 20:23:54,446 - lightrag - INFO - Loaded graph from code\民法\graph_chunk_entity_relation.graphml with 18 nodes, 18 edges
2025-03-07 20:24:41,341 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-07 20:24:43,448 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-07 20:45:46,801 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-07 20:45:46,806 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x000001C2C6B49260>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x000001C2C6B491C0>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x000001C2C5C4D8A0>

2025-03-07 20:45:46,806 - lightrag - INFO - Load KV full_docs with 1 data
2025-03-07 20:45:46,808 - lightrag - INFO - Load KV text_chunks with 1 data
2025-03-07 20:45:46,808 - lightrag - INFO - Load KV llm_response_cache with 4 data
2025-03-07 20:45:46,812 - lightrag - INFO - Loaded graph from code\民法\graph_chunk_entity_relation.graphml with 18 nodes, 18 edges
2025-03-07 20:46:23,073 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-07 20:46:23,073 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x00000285570F94E0>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x00000285570F9440>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x00000285561FD8A0>

2025-03-07 20:46:23,073 - lightrag - INFO - Load KV full_docs with 1 data
2025-03-07 20:46:23,073 - lightrag - INFO - Load KV text_chunks with 1 data
2025-03-07 20:46:23,073 - lightrag - INFO - Load KV llm_response_cache with 4 data
2025-03-07 20:46:23,078 - lightrag - INFO - Loaded graph from code\民法\graph_chunk_entity_relation.graphml with 18 nodes, 18 edges
2025-03-07 20:46:38,653 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-07 20:46:41,200 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-07 21:07:38,514 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-07 21:07:38,515 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x0000017CC0308AE0>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x0000017CC0308A40>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x0000017CBF9780E0>

2025-03-07 21:07:38,515 - lightrag - INFO - Load KV full_docs with 1 data
2025-03-07 21:07:38,515 - lightrag - INFO - Load KV text_chunks with 1 data
2025-03-07 21:07:38,515 - lightrag - INFO - Load KV llm_response_cache with 6 data
2025-03-07 21:07:38,517 - lightrag - INFO - Loaded graph from code\民法\graph_chunk_entity_relation.graphml with 18 nodes, 18 edges
2025-03-07 21:08:34,941 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-07 21:08:37,207 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-07 21:08:51,686 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-07 21:08:52,300 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-07 21:09:24,120 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-07 21:09:24,120 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x000002DFAE6454E0>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x000002DFAE645440>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x000002DFAC77D8A0>

2025-03-07 21:09:24,124 - lightrag - INFO - Load KV full_docs with 1 data
2025-03-07 21:09:24,124 - lightrag - INFO - Load KV text_chunks with 1 data
2025-03-07 21:09:24,129 - lightrag - INFO - Load KV llm_response_cache with 6 data
2025-03-07 21:09:24,133 - lightrag - INFO - Loaded graph from code\民法\graph_chunk_entity_relation.graphml with 18 nodes, 18 edges
2025-03-07 21:10:26,354 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-07 21:10:26,354 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x000001ED5B1D54E0>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x000001ED5B1D5440>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x000001ED5A2DD8A0>

2025-03-07 21:10:26,354 - lightrag - INFO - Load KV full_docs with 1 data
2025-03-07 21:10:26,354 - lightrag - INFO - Load KV text_chunks with 1 data
2025-03-07 21:10:26,354 - lightrag - INFO - Load KV llm_response_cache with 6 data
2025-03-07 21:10:26,366 - lightrag - INFO - Loaded graph from code\民法\graph_chunk_entity_relation.graphml with 18 nodes, 18 edges
2025-03-07 21:10:33,359 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-07 21:10:35,475 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-07 21:11:29,656 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-07 21:11:30,535 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-07 21:13:12,214 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-07 21:13:12,214 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x000002565CF34B80>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x000002565CF34AE0>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x000002565C5A80E0>

2025-03-07 21:13:12,214 - lightrag - INFO - Load KV full_docs with 1 data
2025-03-07 21:13:12,217 - lightrag - INFO - Load KV text_chunks with 1 data
2025-03-07 21:13:12,218 - lightrag - INFO - Load KV llm_response_cache with 6 data
2025-03-07 21:13:12,218 - lightrag - INFO - Loaded graph from code\民法\graph_chunk_entity_relation.graphml with 18 nodes, 18 edges
2025-03-07 21:13:26,624 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-07 21:13:28,660 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-07 21:15:17,475 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-07 21:15:17,475 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x0000019167844AE0>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x0000019167844A40>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x0000019166EB80E0>

2025-03-07 21:15:17,475 - lightrag - INFO - Load KV full_docs with 1 data
2025-03-07 21:15:17,475 - lightrag - INFO - Load KV text_chunks with 1 data
2025-03-07 21:15:17,475 - lightrag - INFO - Load KV llm_response_cache with 8 data
2025-03-07 21:15:17,475 - lightrag - INFO - Loaded graph from code\民法\graph_chunk_entity_relation.graphml with 18 nodes, 18 edges
2025-03-07 21:15:26,853 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-07 21:15:27,816 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-07 21:19:48,943 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-07 21:19:48,943 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x000001D16E974AE0>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x000001D16E974A40>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x000001D16DFE40E0>

2025-03-07 21:19:48,943 - lightrag - INFO - Load KV full_docs with 1 data
2025-03-07 21:19:48,945 - lightrag - INFO - Load KV text_chunks with 1 data
2025-03-07 21:19:48,950 - lightrag - INFO - Load KV llm_response_cache with 8 data
2025-03-07 21:19:48,952 - lightrag - INFO - Loaded graph from code\民法\graph_chunk_entity_relation.graphml with 18 nodes, 18 edges
2025-03-07 21:19:53,062 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-07 21:19:54,328 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-07 21:24:20,695 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-07 21:24:20,696 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x00000288BD7E8D60>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x00000288BD7E8CC0>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x00000288BCE440E0>

2025-03-07 21:24:20,697 - lightrag - INFO - Load KV full_docs with 1 data
2025-03-07 21:24:20,698 - lightrag - INFO - Load KV text_chunks with 1 data
2025-03-07 21:24:20,699 - lightrag - INFO - Load KV llm_response_cache with 9 data
2025-03-07 21:24:20,704 - lightrag - INFO - Loaded graph from code\民法\graph_chunk_entity_relation.graphml with 18 nodes, 18 edges
2025-03-07 21:24:35,588 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-07 21:24:36,529 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-07 21:26:25,285 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-07 21:26:25,285 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x0000023C31C64AE0>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x0000023C31C64A40>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x0000023C312D40E0>

2025-03-07 21:26:25,285 - lightrag - INFO - Load KV full_docs with 1 data
2025-03-07 21:26:25,285 - lightrag - INFO - Load KV text_chunks with 1 data
2025-03-07 21:26:25,285 - lightrag - INFO - Load KV llm_response_cache with 10 data
2025-03-07 21:26:25,285 - lightrag - INFO - Loaded graph from code\民法\graph_chunk_entity_relation.graphml with 18 nodes, 18 edges
2025-03-07 21:26:33,548 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-07 21:26:34,840 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-08 10:04:12,957 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-08 10:04:12,957 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x000002476B5C4AE0>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x000002476B5C4A40>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x000002476AC380E0>

2025-03-08 10:04:12,957 - lightrag - INFO - Load KV full_docs with 1 data
2025-03-08 10:04:12,957 - lightrag - INFO - Load KV text_chunks with 1 data
2025-03-08 10:04:12,957 - lightrag - INFO - Load KV llm_response_cache with 10 data
2025-03-08 10:04:12,965 - lightrag - INFO - Loaded graph from code\民法\graph_chunk_entity_relation.graphml with 18 nodes, 18 edges
2025-03-08 10:04:54,206 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-08 10:04:55,466 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-08 10:05:28,360 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-08 10:05:29,085 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-08 10:13:49,412 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-08 10:13:49,412 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x0000019E20D04B80>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x0000019E20D04AE0>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x0000019E203580E0>

2025-03-08 10:13:49,412 - lightrag - INFO - Load KV full_docs with 1 data
2025-03-08 10:13:49,412 - lightrag - INFO - Load KV text_chunks with 1 data
2025-03-08 10:13:49,412 - lightrag - INFO - Load KV llm_response_cache with 10 data
2025-03-08 10:13:49,428 - lightrag - INFO - Loaded graph from code\民法\graph_chunk_entity_relation.graphml with 18 nodes, 18 edges
2025-03-08 10:14:00,587 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-08 10:14:01,596 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-08 10:22:59,715 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-08 10:22:59,715 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x0000015CE3E14AE0>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x0000015CE3E14A40>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x0000015CE34840E0>

2025-03-08 10:22:59,722 - lightrag - INFO - Load KV full_docs with 1 data
2025-03-08 10:22:59,722 - lightrag - INFO - Load KV text_chunks with 1 data
2025-03-08 10:22:59,722 - lightrag - INFO - Load KV llm_response_cache with 10 data
2025-03-08 10:22:59,725 - lightrag - INFO - Loaded graph from code\民法\graph_chunk_entity_relation.graphml with 18 nodes, 18 edges
2025-03-08 10:23:43,560 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-08 10:23:44,561 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-08 10:24:15,936 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-08 10:24:17,652 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-08 10:24:18,057 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-08 10:31:35,031 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-08 10:31:35,031 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x0000025465E50AE0>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x0000025465E50A40>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x00000254654C3F60>

2025-03-08 10:31:35,031 - lightrag - INFO - Load KV full_docs with 1 data
2025-03-08 10:31:35,031 - lightrag - INFO - Load KV text_chunks with 1 data
2025-03-08 10:31:35,035 - lightrag - INFO - Load KV llm_response_cache with 13 data
2025-03-08 10:31:35,035 - lightrag - INFO - Loaded graph from code\民法\graph_chunk_entity_relation.graphml with 18 nodes, 18 edges
2025-03-08 10:31:41,160 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-08 10:31:43,789 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-08 10:47:51,996 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-08 10:47:51,996 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x000002C0E6138D60>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x000002C0E6138CC0>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x000002C0E5793F60>

2025-03-08 10:47:51,996 - lightrag - INFO - Load KV full_docs with 1 data
2025-03-08 10:47:51,996 - lightrag - INFO - Load KV text_chunks with 1 data
2025-03-08 10:47:51,996 - lightrag - INFO - Load KV llm_response_cache with 14 data
2025-03-08 10:47:51,996 - lightrag - INFO - Loaded graph from code\民法\graph_chunk_entity_relation.graphml with 18 nodes, 18 edges
2025-03-08 10:48:03,218 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-08 10:48:04,428 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-08 10:56:58,336 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-08 10:56:58,336 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x0000018713AD0A40>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x0000018713AD09A0>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x0000018713123F60>

2025-03-08 10:56:58,336 - lightrag - INFO - Load KV full_docs with 1 data
2025-03-08 10:56:58,336 - lightrag - INFO - Load KV text_chunks with 1 data
2025-03-08 10:56:58,336 - lightrag - INFO - Load KV llm_response_cache with 14 data
2025-03-08 10:56:58,336 - lightrag - INFO - Loaded graph from code\民法\graph_chunk_entity_relation.graphml with 18 nodes, 18 edges
2025-03-08 10:57:10,524 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-08 10:57:11,682 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-08 11:01:18,373 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-08 11:01:18,373 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x0000024E0A1D0A40>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x0000024E0A1D09A0>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x0000024E09823F60>

2025-03-08 11:01:18,377 - lightrag - INFO - Load KV full_docs with 1 data
2025-03-08 11:01:18,377 - lightrag - INFO - Load KV text_chunks with 1 data
2025-03-08 11:01:18,378 - lightrag - INFO - Load KV llm_response_cache with 14 data
2025-03-08 11:01:18,379 - lightrag - INFO - Loaded graph from code\民法\graph_chunk_entity_relation.graphml with 18 nodes, 18 edges
2025-03-08 11:01:28,138 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-08 11:01:29,397 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-08 11:01:45,861 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-08 11:01:48,172 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-08 11:02:01,865 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-08 11:02:04,277 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-08 11:02:04,851 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-08 11:03:28,126 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-08 11:03:30,202 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-08 11:03:30,624 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-08 11:03:46,472 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-08 11:03:48,794 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-08 11:07:29,986 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-08 11:07:29,986 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x000001FE5BEDCCC0>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x000001FE5BEDCC20>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x000001FE5B533F60>

2025-03-08 11:07:29,992 - lightrag - INFO - Load KV full_docs with 1 data
2025-03-08 11:07:29,992 - lightrag - INFO - Load KV text_chunks with 1 data
2025-03-08 11:07:29,992 - lightrag - INFO - Load KV llm_response_cache with 22 data
2025-03-08 11:07:29,992 - lightrag - INFO - Loaded graph from code\民法\graph_chunk_entity_relation.graphml with 18 nodes, 18 edges
2025-03-08 11:08:00,092 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-08 11:08:01,144 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-08 11:08:25,123 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-08 11:08:27,014 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-08 11:10:11,271 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-08 11:10:11,271 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x00000223C3378CC0>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x00000223C3378C20>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x00000223C29D3F60>

2025-03-08 11:10:11,271 - lightrag - INFO - Load KV full_docs with 1 data
2025-03-08 11:10:11,271 - lightrag - INFO - Load KV text_chunks with 1 data
2025-03-08 11:10:11,271 - lightrag - INFO - Load KV llm_response_cache with 25 data
2025-03-08 11:10:11,271 - lightrag - INFO - Loaded graph from code\民法\graph_chunk_entity_relation.graphml with 18 nodes, 18 edges
2025-03-08 11:10:26,087 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-08 11:10:27,110 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-08 11:11:24,605 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-08 11:11:26,934 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-08 20:46:01,324 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-08 20:46:01,324 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x0000018E35808CC0>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x0000018E35808C20>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x0000018E34E63F60>

2025-03-08 20:46:01,324 - lightrag - INFO - Load KV full_docs with 1 data
2025-03-08 20:46:01,324 - lightrag - INFO - Load KV text_chunks with 1 data
2025-03-08 20:46:01,324 - lightrag - INFO - Load KV llm_response_cache with 27 data
2025-03-08 20:46:01,324 - lightrag - INFO - Loaded graph from code\民法\graph_chunk_entity_relation.graphml with 18 nodes, 18 edges
2025-03-09 09:44:33,218 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-09 09:44:33,219 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x000001F494F78CC0>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x000001F494F78C20>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x000001F4945D3F60>

2025-03-09 09:44:33,219 - lightrag - INFO - Load KV full_docs with 1 data
2025-03-09 09:44:33,219 - lightrag - INFO - Load KV text_chunks with 1 data
2025-03-09 09:44:33,219 - lightrag - INFO - Load KV llm_response_cache with 27 data
2025-03-09 09:44:33,222 - lightrag - INFO - Loaded graph from code\民法\graph_chunk_entity_relation.graphml with 18 nodes, 18 edges
2025-03-09 14:32:03,189 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-09 14:32:03,189 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x0000022B6CC20A40>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x0000022B6CC209A0>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x0000022B6C293F60>

2025-03-09 14:32:03,191 - lightrag - INFO - Load KV full_docs with 1 data
2025-03-09 14:32:03,191 - lightrag - INFO - Load KV text_chunks with 1 data
2025-03-09 14:32:03,191 - lightrag - INFO - Load KV llm_response_cache with 27 data
2025-03-09 14:32:03,191 - lightrag - INFO - Loaded graph from code\民法\graph_chunk_entity_relation.graphml with 18 nodes, 18 edges
2025-03-09 14:33:49,175 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-09 14:33:50,072 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-09 14:33:50,455 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-09 14:35:06,972 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-09 14:35:08,230 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-09 14:35:08,591 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-09 15:37:10,963 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-09 15:37:10,963 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x00000189651A8CC0>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x00000189651A8C20>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x0000018964803F60>

2025-03-09 15:37:10,963 - lightrag - INFO - Load KV full_docs with 1 data
2025-03-09 15:37:10,963 - lightrag - INFO - Load KV text_chunks with 1 data
2025-03-09 15:37:10,963 - lightrag - INFO - Load KV llm_response_cache with 30 data
2025-03-09 15:37:10,963 - lightrag - INFO - Loaded graph from code\民法\graph_chunk_entity_relation.graphml with 18 nodes, 18 edges
2025-03-09 15:37:22,957 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-09 15:37:23,802 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-09 15:37:24,195 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-09 15:38:37,411 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-09 15:38:37,411 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x000002A47B508CC0>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x000002A47B508C20>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x000002A47AB63F60>

2025-03-09 15:38:37,411 - lightrag - INFO - Load KV full_docs with 1 data
2025-03-09 15:38:37,415 - lightrag - INFO - Load KV text_chunks with 1 data
2025-03-09 15:38:37,415 - lightrag - INFO - Load KV llm_response_cache with 31 data
2025-03-09 15:38:37,418 - lightrag - INFO - Loaded graph from code\民法\graph_chunk_entity_relation.graphml with 18 nodes, 18 edges
2025-03-09 15:38:59,103 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-09 15:38:59,930 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-09 15:39:00,358 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-09 20:17:40,793 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-09 20:17:40,793 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x00000205B22E8CC0>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x00000205B22E8C20>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x00000205B1923F60>

2025-03-09 20:17:40,793 - lightrag - INFO - Load KV full_docs with 1 data
2025-03-09 20:17:40,793 - lightrag - INFO - Load KV text_chunks with 1 data
2025-03-09 20:17:40,793 - lightrag - INFO - Load KV llm_response_cache with 32 data
2025-03-09 20:17:40,793 - lightrag - INFO - Loaded graph from code\民法\graph_chunk_entity_relation.graphml with 18 nodes, 18 edges
2025-03-09 20:18:43,958 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-09 20:18:45,013 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-09 20:18:45,414 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-09 20:36:10,444 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-09 20:36:10,444 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x000001B230B18CC0>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x000001B230B18C20>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x000001B230153F60>

2025-03-09 20:36:10,444 - lightrag - INFO - Load KV full_docs with 1 data
2025-03-09 20:36:10,444 - lightrag - INFO - Load KV text_chunks with 1 data
2025-03-09 20:36:10,444 - lightrag - INFO - Load KV llm_response_cache with 33 data
2025-03-09 20:36:10,444 - lightrag - INFO - Loaded graph from code\民法\graph_chunk_entity_relation.graphml with 18 nodes, 18 edges
2025-03-09 20:42:20,039 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-09 20:42:20,039 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x000001ADB38B8CC0>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x000001ADB38B8C20>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x000001ADB2EF3F60>

2025-03-09 20:42:20,039 - lightrag - INFO - Load KV full_docs with 1 data
2025-03-09 20:42:20,039 - lightrag - INFO - Load KV text_chunks with 1 data
2025-03-09 20:42:20,039 - lightrag - INFO - Load KV llm_response_cache with 33 data
2025-03-09 20:42:20,039 - lightrag - INFO - Loaded graph from code\民法\graph_chunk_entity_relation.graphml with 18 nodes, 18 edges
2025-03-09 20:43:02,748 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-09 20:43:02,748 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x000002263CF88CC0>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x000002263CF88C20>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x000002263C5C3F60>

2025-03-09 20:43:02,748 - lightrag - INFO - Load KV full_docs with 1 data
2025-03-09 20:43:02,748 - lightrag - INFO - Load KV text_chunks with 1 data
2025-03-09 20:43:02,748 - lightrag - INFO - Load KV llm_response_cache with 33 data
2025-03-09 20:43:02,748 - lightrag - INFO - Loaded graph from code\民法\graph_chunk_entity_relation.graphml with 18 nodes, 18 edges
2025-03-09 20:43:26,763 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-09 20:43:26,763 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x00000299D93BD120>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x00000299D93BD080>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x00000299D8A17F60>

2025-03-09 20:43:26,763 - lightrag - INFO - Load KV full_docs with 1 data
2025-03-09 20:43:26,763 - lightrag - INFO - Load KV text_chunks with 1 data
2025-03-09 20:43:26,763 - lightrag - INFO - Load KV llm_response_cache with 33 data
2025-03-09 20:43:26,763 - lightrag - INFO - Loaded graph from code\民法\graph_chunk_entity_relation.graphml with 18 nodes, 18 edges
2025-03-09 20:51:45,879 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-09 20:51:47,476 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-09 20:51:47,938 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-09 20:56:08,003 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-09 20:56:09,947 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-09 20:56:10,451 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-09 21:08:04,053 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-09 21:08:04,053 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x0000020189AED120>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x0000020189AED080>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x0000020189127F60>

2025-03-09 21:08:04,053 - lightrag - INFO - Load KV full_docs with 1 data
2025-03-09 21:08:04,053 - lightrag - INFO - Load KV text_chunks with 1 data
2025-03-09 21:08:04,053 - lightrag - INFO - Load KV llm_response_cache with 37 data
2025-03-09 21:08:04,064 - lightrag - INFO - Loaded graph from code\民法\graph_chunk_entity_relation.graphml with 18 nodes, 18 edges
2025-03-09 21:24:52,612 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-09 21:24:52,612 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x00000117D6E4D120>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x00000117D6E4D080>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x00000117D64A7F60>

2025-03-09 21:24:52,612 - lightrag - INFO - Load KV full_docs with 1 data
2025-03-09 21:24:52,612 - lightrag - INFO - Load KV text_chunks with 1 data
2025-03-09 21:24:52,612 - lightrag - INFO - Load KV llm_response_cache with 37 data
2025-03-09 21:24:52,612 - lightrag - INFO - Loaded graph from code\民法\graph_chunk_entity_relation.graphml with 18 nodes, 18 edges
2025-03-09 21:25:14,626 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-09 21:25:15,478 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-09 21:25:15,865 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-09 21:28:02,318 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-09 21:28:04,235 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-09 21:28:04,728 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 08:26:00,090 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-10 08:26:00,090 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x0000027BAFE7D120>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x0000027BAFE7D080>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x0000027BAF4D7F60>

2025-03-10 08:26:00,090 - lightrag - INFO - Load KV full_docs with 1 data
2025-03-10 08:26:00,090 - lightrag - INFO - Load KV text_chunks with 1 data
2025-03-10 08:26:00,090 - lightrag - INFO - Load KV llm_response_cache with 40 data
2025-03-10 08:26:00,101 - lightrag - INFO - Loaded graph from code\民法\graph_chunk_entity_relation.graphml with 18 nodes, 18 edges
2025-03-10 08:52:52,944 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-10 08:52:52,944 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x000002843C3FD120>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x000002843C3FD080>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x000002843BA37F60>

2025-03-10 08:52:52,944 - lightrag - INFO - Load KV full_docs with 1 data
2025-03-10 08:52:52,944 - lightrag - INFO - Load KV text_chunks with 1 data
2025-03-10 08:52:52,944 - lightrag - INFO - Load KV llm_response_cache with 40 data
2025-03-10 08:52:52,944 - lightrag - INFO - Loaded graph from code\民法\graph_chunk_entity_relation.graphml with 18 nodes, 18 edges
2025-03-10 08:54:08,358 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 08:54:09,483 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 08:54:09,922 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 09:30:07,225 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 09:30:09,246 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 09:30:09,930 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 09:30:32,292 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 09:30:34,537 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 09:30:35,133 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 11:01:48,694 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 11:01:48,985 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 11:01:51,151 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 11:01:51,315 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 11:01:51,828 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 11:01:52,083 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 11:03:16,002 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 11:03:18,443 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 11:03:19,148 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 11:05:32,809 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 11:05:34,831 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 11:05:35,597 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 11:06:04,757 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 11:06:07,209 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 11:06:07,825 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 11:08:01,725 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 11:08:04,837 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 11:08:05,608 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 11:08:23,737 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 11:08:26,070 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 11:08:26,991 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 13:37:46,606 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-10 13:37:46,606 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x000001E2DF05D120>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x000001E2DF05D080>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x000001E2DE6B7F60>

2025-03-10 13:37:46,606 - lightrag - INFO - Load KV full_docs with 1 data
2025-03-10 13:37:46,606 - lightrag - INFO - Load KV text_chunks with 1 data
2025-03-10 13:37:46,606 - lightrag - INFO - Load KV llm_response_cache with 58 data
2025-03-10 13:37:46,606 - lightrag - INFO - Loaded graph from code\民法\graph_chunk_entity_relation.graphml with 18 nodes, 18 edges
2025-03-10 13:42:32,478 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 13:42:34,297 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 13:42:35,051 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 13:47:31,198 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 13:47:33,233 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 13:47:34,428 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 13:49:25,067 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 13:49:27,384 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 13:49:28,014 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 13:49:52,837 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 13:49:54,844 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 13:49:55,425 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 13:50:13,435 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 13:50:17,478 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 13:50:18,127 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 14:00:17,408 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 14:00:20,603 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 14:00:21,775 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 14:08:24,939 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-10 14:08:24,939 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x0000029B102ED120>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x0000029B102ED080>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x0000029B0F927F60>

2025-03-10 14:08:24,939 - lightrag - INFO - Load KV full_docs with 1 data
2025-03-10 14:08:24,939 - lightrag - INFO - Load KV text_chunks with 1 data
2025-03-10 14:08:24,939 - lightrag - INFO - Load KV llm_response_cache with 69 data
2025-03-10 14:08:24,939 - lightrag - INFO - Loaded graph from code\民法\graph_chunk_entity_relation.graphml with 18 nodes, 18 edges
2025-03-10 14:17:45,794 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-10 14:17:45,794 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x000001EF447CD120>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x000001EF447CD080>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x000001EF43E27F60>

2025-03-10 14:17:45,794 - lightrag - INFO - Load KV full_docs with 1 data
2025-03-10 14:17:45,794 - lightrag - INFO - Load KV text_chunks with 1 data
2025-03-10 14:17:45,794 - lightrag - INFO - Load KV llm_response_cache with 69 data
2025-03-10 14:17:45,794 - lightrag - INFO - Loaded graph from code\民法\graph_chunk_entity_relation.graphml with 18 nodes, 18 edges
2025-03-10 14:18:03,084 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 14:18:04,617 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 14:18:05,299 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 14:18:21,488 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 14:18:22,045 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 14:18:23,953 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 14:18:24,039 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 14:18:24,758 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 14:18:24,760 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 14:20:14,017 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 14:20:16,397 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 14:20:17,270 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 14:20:29,571 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 14:20:32,678 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 14:20:33,348 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 14:20:47,516 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 14:20:50,451 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 14:20:51,128 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 14:21:51,440 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-10 14:21:51,440 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x000002A347B7D120>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x000002A347B7D080>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x000002A3471D7F60>

2025-03-10 14:21:51,444 - lightrag - INFO - Load KV full_docs with 1 data
2025-03-10 14:21:51,444 - lightrag - INFO - Load KV text_chunks with 1 data
2025-03-10 14:21:51,444 - lightrag - INFO - Load KV llm_response_cache with 78 data
2025-03-10 14:21:51,444 - lightrag - INFO - Loaded graph from code\民法\graph_chunk_entity_relation.graphml with 18 nodes, 18 edges
2025-03-10 14:22:19,997 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 14:22:21,738 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 14:22:22,126 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 14:22:51,715 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 14:22:53,291 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 14:22:53,800 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 14:23:52,148 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 14:23:55,713 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 14:23:56,524 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 14:24:26,098 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 14:24:28,365 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 14:24:29,147 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 14:24:53,586 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 14:24:55,446 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 14:24:56,105 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 14:25:16,215 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 14:25:18,957 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 14:25:19,553 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 14:28:12,464 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-10 14:28:12,464 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x0000018D8DAED120>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x0000018D8DAED080>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x0000018D8D127F60>

2025-03-10 14:28:12,464 - lightrag - INFO - Load KV full_docs with 1 data
2025-03-10 14:28:12,464 - lightrag - INFO - Load KV text_chunks with 1 data
2025-03-10 14:28:12,464 - lightrag - INFO - Load KV llm_response_cache with 90 data
2025-03-10 14:28:12,464 - lightrag - INFO - Loaded graph from code\民法\graph_chunk_entity_relation.graphml with 18 nodes, 18 edges
2025-03-10 14:30:34,103 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 14:30:35,440 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 14:30:35,928 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 14:33:36,808 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 14:33:39,764 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 14:33:40,397 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 14:51:34,348 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-10 14:51:34,348 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x00000273EC2AD120>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x00000273EC2AD080>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x00000273EB907F60>

2025-03-10 14:51:34,348 - lightrag - INFO - Load KV full_docs with 1 data
2025-03-10 14:51:34,348 - lightrag - INFO - Load KV text_chunks with 1 data
2025-03-10 14:51:34,348 - lightrag - INFO - Load KV llm_response_cache with 93 data
2025-03-10 14:51:34,351 - lightrag - INFO - Loaded graph from code\民法\graph_chunk_entity_relation.graphml with 18 nodes, 18 edges
2025-03-10 14:51:49,779 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 14:51:52,149 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 14:51:52,870 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 14:52:25,770 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 14:52:28,532 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 14:52:29,377 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 14:52:51,085 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 14:52:53,080 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 14:52:53,698 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 14:55:27,500 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-10 14:55:27,500 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x00000131B7CDD120>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x00000131B7CDD080>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x00000131B7337F60>

2025-03-10 14:55:27,504 - lightrag - INFO - Load KV full_docs with 1 data
2025-03-10 14:55:27,504 - lightrag - INFO - Load KV text_chunks with 1 data
2025-03-10 14:55:27,504 - lightrag - INFO - Load KV llm_response_cache with 98 data
2025-03-10 14:55:27,504 - lightrag - INFO - Loaded graph from code\民法\graph_chunk_entity_relation.graphml with 18 nodes, 18 edges
2025-03-10 14:55:37,971 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 14:55:38,876 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 14:55:39,436 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 14:56:06,111 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 14:56:07,977 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 14:56:08,665 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 14:56:44,501 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 14:56:46,360 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 14:56:46,813 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 14:57:02,288 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 14:57:04,328 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 14:57:04,777 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 14:57:59,716 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 14:58:02,102 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 14:58:02,799 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 14:58:58,426 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 14:59:00,184 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 14:59:00,654 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 15:03:18,574 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 15:03:20,516 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 15:03:20,946 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 15:04:43,961 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 15:04:46,833 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 15:04:47,744 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 15:11:37,765 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-10 15:11:37,765 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x0000021C6FE4D120>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x0000021C6FE4D080>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x0000021C6F4A7F60>

2025-03-10 15:11:37,765 - lightrag - INFO - Load KV full_docs with 1 data
2025-03-10 15:11:37,765 - lightrag - INFO - Load KV text_chunks with 1 data
2025-03-10 15:11:37,765 - lightrag - INFO - Load KV llm_response_cache with 113 data
2025-03-10 15:11:37,765 - lightrag - INFO - Loaded graph from code\民法\graph_chunk_entity_relation.graphml with 18 nodes, 18 edges
2025-03-10 15:11:53,977 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 15:11:55,614 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 15:11:56,437 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 15:19:40,208 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-10 15:19:40,208 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x000002AE4BA40EA0>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x000002AE4BA40E00>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x000002AE4B0B7F60>

2025-03-10 15:19:40,208 - lightrag - INFO - Load KV full_docs with 1 data
2025-03-10 15:19:40,212 - lightrag - INFO - Load KV text_chunks with 1 data
2025-03-10 15:19:40,212 - lightrag - INFO - Load KV llm_response_cache with 114 data
2025-03-10 15:19:40,212 - lightrag - INFO - Loaded graph from code\民法\graph_chunk_entity_relation.graphml with 18 nodes, 18 edges
2025-03-10 15:19:51,538 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 15:19:53,194 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 15:19:53,948 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 15:20:49,270 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-10 15:20:49,270 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x0000022D07860EA0>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x0000022D07860E00>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x0000022D06ED7F60>

2025-03-10 15:20:49,272 - lightrag - INFO - Load KV full_docs with 1 data
2025-03-10 15:20:49,273 - lightrag - INFO - Load KV text_chunks with 1 data
2025-03-10 15:20:49,274 - lightrag - INFO - Load KV llm_response_cache with 115 data
2025-03-10 15:20:49,277 - lightrag - INFO - Loaded graph from code\民法\graph_chunk_entity_relation.graphml with 18 nodes, 18 edges
2025-03-10 15:21:28,469 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 15:21:29,450 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 15:21:29,904 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 15:26:29,677 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-10 15:26:29,677 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x000001E63644D120>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x000001E63644D080>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x000001E635A87F60>

2025-03-10 15:26:29,677 - lightrag - INFO - Load KV full_docs with 1 data
2025-03-10 15:26:29,677 - lightrag - INFO - Load KV text_chunks with 1 data
2025-03-10 15:26:29,677 - lightrag - INFO - Load KV llm_response_cache with 116 data
2025-03-10 15:26:29,677 - lightrag - INFO - Loaded graph from code\民法\graph_chunk_entity_relation.graphml with 18 nodes, 18 edges
2025-03-10 15:26:46,551 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 15:26:47,674 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 15:26:48,178 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 15:27:23,035 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 15:27:24,818 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 15:27:25,345 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 15:32:33,106 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-10 15:32:33,106 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x0000025698B1D120>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x0000025698B1D080>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x0000025698157F60>

2025-03-10 15:32:33,106 - lightrag - INFO - Load KV full_docs with 1 data
2025-03-10 15:32:33,106 - lightrag - INFO - Load KV text_chunks with 1 data
2025-03-10 15:32:33,106 - lightrag - INFO - Load KV llm_response_cache with 119 data
2025-03-10 15:32:33,120 - lightrag - INFO - Loaded graph from code\民法\graph_chunk_entity_relation.graphml with 18 nodes, 18 edges
2025-03-10 15:32:48,836 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 15:32:50,711 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 15:32:51,543 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 15:33:59,271 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-10 15:33:59,271 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x0000014BC8F1D120>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x0000014BC8F1D080>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x0000014BC8577F60>

2025-03-10 15:33:59,271 - lightrag - INFO - Load KV full_docs with 1 data
2025-03-10 15:33:59,271 - lightrag - INFO - Load KV text_chunks with 1 data
2025-03-10 15:33:59,282 - lightrag - INFO - Load KV llm_response_cache with 120 data
2025-03-10 15:33:59,285 - lightrag - INFO - Loaded graph from code\民法\graph_chunk_entity_relation.graphml with 18 nodes, 18 edges
2025-03-10 15:34:17,299 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 15:34:18,370 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 15:34:18,858 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 15:37:43,743 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-10 15:37:43,743 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x00000269D77AD120>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x00000269D77AD080>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x00000269D6E07F60>

2025-03-10 15:37:43,743 - lightrag - INFO - Load KV full_docs with 1 data
2025-03-10 15:37:43,743 - lightrag - INFO - Load KV text_chunks with 1 data
2025-03-10 15:37:43,743 - lightrag - INFO - Load KV llm_response_cache with 121 data
2025-03-10 15:37:43,747 - lightrag - INFO - Loaded graph from code\民法\graph_chunk_entity_relation.graphml with 18 nodes, 18 edges
2025-03-10 15:37:52,348 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 15:37:53,790 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 15:37:54,434 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 15:46:29,428 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-10 15:46:29,432 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x0000027725CED120>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x0000027725CED080>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x0000027725327F60>

2025-03-10 15:46:29,432 - lightrag - INFO - Load KV full_docs with 1 data
2025-03-10 15:46:29,433 - lightrag - INFO - Load KV text_chunks with 1 data
2025-03-10 15:46:29,433 - lightrag - INFO - Load KV llm_response_cache with 122 data
2025-03-10 15:46:29,437 - lightrag - INFO - Loaded graph from code\民法\graph_chunk_entity_relation.graphml with 18 nodes, 18 edges
2025-03-10 15:53:05,255 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-10 15:53:05,255 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x00000147F8DF1120>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x00000147F8DF1080>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x00000147F8447F60>

2025-03-10 15:53:05,255 - lightrag - INFO - Load KV full_docs with 1 data
2025-03-10 15:53:05,255 - lightrag - INFO - Load KV text_chunks with 1 data
2025-03-10 15:53:05,255 - lightrag - INFO - Load KV llm_response_cache with 122 data
2025-03-10 15:53:05,255 - lightrag - INFO - Loaded graph from code\民法\graph_chunk_entity_relation.graphml with 18 nodes, 18 edges
2025-03-10 15:53:24,058 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 15:53:25,382 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 15:53:25,793 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 16:02:38,925 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-10 16:02:38,925 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x000001D770B9D120>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x000001D770B9D080>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x000001D7701F7F60>

2025-03-10 16:02:38,925 - lightrag - INFO - Load KV full_docs with 1 data
2025-03-10 16:02:38,925 - lightrag - INFO - Load KV text_chunks with 1 data
2025-03-10 16:02:38,925 - lightrag - INFO - Load KV llm_response_cache with 123 data
2025-03-10 16:02:38,925 - lightrag - INFO - Loaded graph from code\民法\graph_chunk_entity_relation.graphml with 18 nodes, 18 edges
2025-03-10 16:02:53,915 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 16:02:55,649 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 16:02:56,281 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 16:03:25,052 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 16:03:27,538 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 16:03:28,436 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 16:10:09,335 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-10 16:10:09,335 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x000001DE09AED120>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x000001DE09AED080>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x000001DE09127F60>

2025-03-10 16:10:09,335 - lightrag - INFO - Load KV full_docs with 1 data
2025-03-10 16:10:09,339 - lightrag - INFO - Load KV text_chunks with 1 data
2025-03-10 16:10:09,339 - lightrag - INFO - Load KV llm_response_cache with 126 data
2025-03-10 16:10:09,344 - lightrag - INFO - Loaded graph from code\民法\graph_chunk_entity_relation.graphml with 18 nodes, 18 edges
2025-03-10 16:11:58,544 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-10 16:11:58,544 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x0000024C23D7D120>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x0000024C23D7D080>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x0000024C233D7F60>

2025-03-10 16:11:58,544 - lightrag - INFO - Load KV full_docs with 1 data
2025-03-10 16:11:58,544 - lightrag - INFO - Load KV text_chunks with 1 data
2025-03-10 16:11:58,544 - lightrag - INFO - Load KV llm_response_cache with 126 data
2025-03-10 16:11:58,544 - lightrag - INFO - Loaded graph from code\民法\graph_chunk_entity_relation.graphml with 18 nodes, 18 edges
2025-03-10 16:14:32,207 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 16:14:33,884 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 16:14:34,516 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 16:16:16,039 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 16:16:18,784 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 16:16:19,234 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 16:30:04,718 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-10 16:30:04,718 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x000002AF26B1D120>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x000002AF26B1D080>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x000002AF26157F60>

2025-03-10 16:30:04,718 - lightrag - INFO - Load KV full_docs with 1 data
2025-03-10 16:30:04,721 - lightrag - INFO - Load KV text_chunks with 1 data
2025-03-10 16:30:04,721 - lightrag - INFO - Load KV llm_response_cache with 129 data
2025-03-10 16:30:04,721 - lightrag - INFO - Loaded graph from code\民法\graph_chunk_entity_relation.graphml with 18 nodes, 18 edges
2025-03-10 16:30:34,649 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 16:30:35,562 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 16:30:36,138 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 16:31:07,100 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 16:31:09,806 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 16:31:10,689 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 16:31:55,141 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 16:31:57,648 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 16:31:58,424 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 16:32:39,244 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 16:32:41,980 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 16:32:42,977 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 16:35:34,194 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-10 16:35:34,194 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x000001AAC2A3D120>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x000001AAC2A3D080>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x000001AAC2097F60>

2025-03-10 16:35:34,194 - lightrag - INFO - Load KV full_docs with 1 data
2025-03-10 16:35:34,194 - lightrag - INFO - Load KV text_chunks with 1 data
2025-03-10 16:35:34,194 - lightrag - INFO - Load KV llm_response_cache with 136 data
2025-03-10 16:35:34,194 - lightrag - INFO - Loaded graph from code\民法\graph_chunk_entity_relation.graphml with 18 nodes, 18 edges
2025-03-10 16:35:35,765 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 16:35:36,771 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 16:35:37,173 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 16:35:58,691 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 16:36:02,789 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 16:36:03,602 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 16:37:41,287 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 16:37:44,113 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 16:37:44,914 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 16:42:16,861 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-10 16:42:16,861 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x000001DF5632D120>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x000001DF5632D080>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x000001DF55987F60>

2025-03-10 16:42:16,861 - lightrag - INFO - Load KV full_docs with 1 data
2025-03-10 16:42:16,861 - lightrag - INFO - Load KV text_chunks with 1 data
2025-03-10 16:42:16,861 - lightrag - INFO - Load KV llm_response_cache with 141 data
2025-03-10 16:42:16,877 - lightrag - INFO - Loaded graph from code\民法\graph_chunk_entity_relation.graphml with 18 nodes, 18 edges
2025-03-10 16:42:32,051 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 16:42:33,548 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 16:42:34,213 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 16:42:45,598 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 16:42:48,309 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 16:42:48,946 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 16:43:17,808 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 16:43:20,326 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 16:43:21,089 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 16:43:23,808 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 16:43:25,099 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 16:43:25,886 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 16:53:01,087 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-10 16:53:01,087 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x00000273D215D120>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x00000273D215D080>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x00000273D17B7F60>

2025-03-10 16:53:01,092 - lightrag - INFO - Load KV full_docs with 1 data
2025-03-10 16:53:01,092 - lightrag - INFO - Load KV text_chunks with 1 data
2025-03-10 16:53:01,092 - lightrag - INFO - Load KV llm_response_cache with 146 data
2025-03-10 16:53:01,096 - lightrag - INFO - Loaded graph from code\民法\graph_chunk_entity_relation.graphml with 18 nodes, 18 edges
2025-03-10 16:53:07,331 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 16:53:08,347 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 16:53:08,781 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 16:54:50,349 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-10 16:54:50,349 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x0000025E3D95D120>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x0000025E3D95D080>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x0000025E3CF97F60>

2025-03-10 16:54:50,364 - lightrag - INFO - Load KV full_docs with 1 data
2025-03-10 16:54:50,364 - lightrag - INFO - Load KV text_chunks with 1 data
2025-03-10 16:54:50,364 - lightrag - INFO - Load KV llm_response_cache with 147 data
2025-03-10 16:54:50,364 - lightrag - INFO - Loaded graph from code\民法\graph_chunk_entity_relation.graphml with 18 nodes, 18 edges
2025-03-10 16:55:01,864 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 16:55:02,771 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 16:55:03,175 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 17:00:31,221 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-10 17:00:31,221 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x0000017EB41BD120>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x0000017EB41BD080>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x0000017EB37F7F60>

2025-03-10 17:00:31,222 - lightrag - INFO - Load KV full_docs with 1 data
2025-03-10 17:00:31,223 - lightrag - INFO - Load KV text_chunks with 1 data
2025-03-10 17:00:31,224 - lightrag - INFO - Load KV llm_response_cache with 148 data
2025-03-10 17:00:31,225 - lightrag - INFO - Loaded graph from code\民法\graph_chunk_entity_relation.graphml with 18 nodes, 18 edges
2025-03-10 17:00:34,796 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 17:00:36,182 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 17:00:36,844 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 17:02:48,447 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 17:02:51,210 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 17:02:52,054 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 17:04:28,345 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 17:04:31,293 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 17:04:32,134 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 17:06:48,506 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 17:06:51,193 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 17:06:51,982 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 17:11:04,684 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 17:11:07,664 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 17:11:08,473 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 17:11:56,670 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 17:11:59,435 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 17:12:00,187 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 17:20:52,366 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 17:20:55,078 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 17:20:55,715 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 17:21:13,533 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 17:21:16,550 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 17:21:17,534 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 17:26:15,821 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 17:26:18,958 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 17:26:19,563 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 17:30:12,611 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 17:30:15,429 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 17:30:16,126 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 17:30:30,059 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 17:30:32,871 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 17:30:33,565 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 17:30:42,150 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 17:30:45,151 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 17:30:45,976 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 17:32:51,899 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 17:32:55,136 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 17:32:55,801 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 17:35:09,048 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 17:35:12,286 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 17:35:13,303 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 17:37:32,448 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-10 17:37:32,448 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x000001D021BF1120>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x000001D021BF1080>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x000001D021227F60>

2025-03-10 17:37:32,448 - lightrag - INFO - Load KV full_docs with 1 data
2025-03-10 17:37:32,448 - lightrag - INFO - Load KV text_chunks with 1 data
2025-03-10 17:37:32,448 - lightrag - INFO - Load KV llm_response_cache with 175 data
2025-03-10 17:37:32,459 - lightrag - INFO - Loaded graph from code\民法\graph_chunk_entity_relation.graphml with 18 nodes, 18 edges
2025-03-10 17:37:45,838 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 17:37:47,260 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 17:37:47,735 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 17:42:19,632 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-10 17:42:19,632 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x0000024FCEC2D120>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x0000024FCEC2D080>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x0000024FCE287F60>

2025-03-10 17:42:19,632 - lightrag - INFO - Load KV full_docs with 1 data
2025-03-10 17:42:19,632 - lightrag - INFO - Load KV text_chunks with 1 data
2025-03-10 17:42:19,632 - lightrag - INFO - Load KV llm_response_cache with 176 data
2025-03-10 17:42:19,640 - lightrag - INFO - Loaded graph from code\民法\graph_chunk_entity_relation.graphml with 18 nodes, 18 edges
2025-03-10 17:42:34,051 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 17:42:35,832 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 17:42:36,708 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 17:42:50,412 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 17:42:52,940 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 17:42:53,579 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 17:43:18,510 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 17:43:22,359 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 17:43:23,127 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 17:43:28,439 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 17:43:29,548 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 17:43:30,335 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-10 17:44:24,087 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-10 17:44:27,771 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-10 17:44:28,636 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-11 14:11:38,876 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-11 14:11:38,877 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x000001F40FC7D120>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x000001F40FC7D080>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x000001F40F2D7F60>

2025-03-11 14:11:38,877 - lightrag - INFO - Load KV full_docs with 1 data
2025-03-11 14:11:38,877 - lightrag - INFO - Load KV text_chunks with 1 data
2025-03-11 14:11:38,879 - lightrag - INFO - Load KV llm_response_cache with 183 data
2025-03-11 14:11:38,881 - lightrag - INFO - Loaded graph from code\民法\graph_chunk_entity_relation.graphml with 18 nodes, 18 edges
2025-03-11 14:12:11,293 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-11 14:12:11,293 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x0000018471D11120>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x0000018471D11080>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x0000018471367F60>

2025-03-11 14:12:11,294 - lightrag - INFO - Load KV full_docs with 1 data
2025-03-11 14:12:11,295 - lightrag - INFO - Load KV text_chunks with 1 data
2025-03-11 14:12:11,297 - lightrag - INFO - Load KV llm_response_cache with 183 data
2025-03-11 14:12:11,299 - lightrag - INFO - Loaded graph from code\民法\graph_chunk_entity_relation.graphml with 18 nodes, 18 edges
2025-03-11 14:12:37,704 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-11 14:12:38,796 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-11 14:12:39,457 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-11 14:14:16,278 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-11 14:14:18,052 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-11 14:14:18,559 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
2025-03-11 14:14:48,561 - lightrag - INFO - Logger initialized for working directory: code\民法
2025-03-11 14:14:48,561 - lightrag - DEBUG - LightRAG init with param:
  working_dir = code\民法,
  chunk_token_size = 1200,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1024, 'max_token_size': 32, 'func': <function embedding_func at 0x0000028EA5ADD120>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function llm_model_func at 0x0000028EA5ADD080>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  llm_model_kwargs = {},
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x0000028EA5117F60>

2025-03-11 14:14:48,561 - lightrag - INFO - Load KV full_docs with 1 data
2025-03-11 14:14:48,562 - lightrag - INFO - Load KV text_chunks with 1 data
2025-03-11 14:14:48,563 - lightrag - INFO - Load KV llm_response_cache with 186 data
2025-03-11 14:14:48,564 - lightrag - INFO - Loaded graph from code\民法\graph_chunk_entity_relation.graphml with 18 nodes, 18 edges
2025-03-11 14:15:14,677 - lightrag - INFO - Creating a new event loop in a sub-thread.
2025-03-11 14:15:15,379 - lightrag - INFO - Local query uses 15 entites, 18 relations, 1 text units
2025-03-11 14:15:15,709 - lightrag - INFO - Global query uses 18 entites, 18 relations, 1 text units
